{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2c1ada",
   "metadata": {
    "id": "aa2c1ada"
   },
   "source": [
    "# Dreambooth\n",
    "### Notebook implementation by Joe Penna (@MysteryGuitarM on Twitter) - Improvements by David Bielejeski\n",
    "Latest information on:\n",
    "https://github.com/JoePenna/Dreambooth-Stable-Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b971cc0",
   "metadata": {
    "id": "7b971cc0"
   },
   "source": [
    "## Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef27dc0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BUILD ENV\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    " !pip install omegaconf\n",
    " !pip install einops\n",
    " !pip install pytorch-lightning==1.6.5\n",
    " !pip install test-tube\n",
    " !pip install transformers\n",
    " !pip install kornia\n",
    " !pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    " !pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    " !pip install setuptools==59.5.0\n",
    " !pip install pillow==9.0.1\n",
    " !pip install torchmetrics==0.6.0\n",
    " !pip install -e .\n",
    " !pip install protobuf==3.20.1\n",
    " !pip install gdown\n",
    " !pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    " !pip install huggingface_hub\n",
    " !pip install captionizer==1.0.1\n",
    " !pip install ipywidgets\n",
    "\n",
    " clear_output()\n",
    " print(\"✅ Dependencies successfully installed\")\n",
    "\n",
    "except:\n",
    " print(\"❌ Error installing dependencies\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479fa8d",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Download the 1.5 model from hugging face\n",
    "You can also provide your own v1.* model for training by uploading it and renaming it to \"model.ckpt\".  It should be in the same directory as dreambooth_runpod_joepenna.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4739408",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the 1.5 sd model\n",
    "from IPython.display import clear_output\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "downloaded_model_path = hf_hub_download(\n",
    " repo_id=\"panopstor/EveryDream\",\n",
    " filename=\"sd_v1-5_vae.ckpt\"\n",
    ")\n",
    "\n",
    "# Move the sd_v1-5_vae.ckpt to the root of this directory as \"model.ckpt\"\n",
    "actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
    "!mv {actual_locations_of_model_blob[-1]} model.ckpt\n",
    "clear_output()\n",
    "print(\"✅ model.ckpt successfully downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dreambooth Training Environment Setup\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5713c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%run juptyer-notebook-helpers/create-config-form-inputs.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e50df",
   "metadata": {
    "id": "ad4e50df"
   },
   "source": [
    "## Training\n",
    "\n",
    "If training a person or subject, keep an eye on your project's `logs/{folder}/images/train/samples_scaled_gs-00xxxx` generations.\n",
    "\n",
    "If training a style, keep an eye on your project's `logs/{folder}/images/train/samples_gs-00xxxx` generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
   "metadata": {
    "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "clear_output()\n",
    "\n",
    "# parse the config file \"joepenna-dreambooth-configs/active-config.json\"\n",
    "config_file_path = \"./joepenna-dreambooth-configs/active-config.json\";\n",
    "if not os.path.exists(config_file_path):\n",
    " print(f\"{config_file_path} not found.\", file=sys.stderr)\n",
    "else:\n",
    " config_file = open(config_file_path)\n",
    " config_parsed = json.load(config_file)\n",
    " print(\"✅ Loaded the config file, proceeding to training\")\n",
    " print()\n",
    " print(\"active-config.json\")\n",
    " print(\"------------------\")\n",
    " print(json.dumps(config_parsed, indent=4))\n",
    "\n",
    " reg_data_root = \"/workspace/Dreambooth-Stable-Diffusion/regularization_images/\" + config_parsed.dataset\n",
    "\n",
    " leftover_training_files = [\"./training_images/.ipynb_checkpoints\", \"./regularization_images/.ipynb_checkpoints\"]\n",
    " for i, ipynb_checkpoint_folder in enumerate(leftover_training_files):\n",
    "  if os.path.exists(ipynb_checkpoint_folder):\n",
    "   shutil.rmtree(ipynb_checkpoint_folder)\n",
    "\n",
    " !python \"main.py\" \\\n",
    "     --base \"configs/stable-diffusion/v1-finetune_unfrozen.yaml\" \\\n",
    "     -t \\\n",
    "     --actual_resume \"model.ckpt\" \\\n",
    "     --reg_data_root \"{reg_data_root}\" \\\n",
    "     -n \"{config_parsed.project_name}\" \\\n",
    "     --gpus 0, \\\n",
    "     --data_root \"/workspace/Dreambooth-Stable-Diffusion/training_images\" \\\n",
    "     --max_training_steps {config_parsed.max_training_steps} \\\n",
    "     --class_word \"{config_parsed.class_word}\" \\\n",
    "     --token \"{config_parsed.token}\" \\\n",
    "     --no-test \\\n",
    "     --flip_p {config.flip_percent} \\\n",
    "     --learning_rate {config_parsed.learning_rate} \\\n",
    "     --save_every_x_steps {config_parsed.save_every_x_steps}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49d0bd",
   "metadata": {},
   "source": [
    "## Copy and name the checkpoint file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b05c16",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def create_checkpoint_file_name(\n",
    "        config_parsed,\n",
    "        date,\n",
    "        training_images_count,\n",
    "        training_steps,\n",
    "):\n",
    " return f\"{date}_{config_parsed.project_name}_\" \\\n",
    "        f\"{training_steps}_steps_\" \\\n",
    "        f\"{training_images_count}_training_images_\" \\\n",
    "        f\"{config_parsed.token}_token_\" \\\n",
    "        f\"{config_parsed.class_word}_class_word.ckpt\".replace(\" \", \"_\")\n",
    "\n",
    "# parse the config file \"joepenna-dreambooth-configs/active-config.json\"\n",
    "config_file_path = \"./joepenna-dreambooth-configs/active-config.json\";\n",
    "if not os.path.exists(config_file_path):\n",
    " print(f\"{config_file_path} not found.\", file=sys.stderr)\n",
    "else:\n",
    "\n",
    " config_file = open(config_file_path)\n",
    " config_parsed = json.load(config_file)\n",
    " training_images_count = str(len(glob.glob(\"./training_images/*\")))\n",
    " date_string = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "\n",
    " trained_models_path = \"./trained_models\"\n",
    " if not os.path.exists(trained_models_path):\n",
    "  os.mkdir(trained_models_path)\n",
    "\n",
    " # copy the config file to the model directory as well\n",
    " shutil.copy(config_file_path, f\"{trained_models_path}/{config_parsed.config_file_name}\")\n",
    "\n",
    " latest_training_directory = glob.glob(\"./logs/*\")[-1]\n",
    "\n",
    "\n",
    " if config_parsed.save_every_x_steps == 0:\n",
    "  # Copy the checkpoint into our `trained_models` folder\n",
    "  last_checkpoint_file = f\"{latest_training_directory}/checkpoints/last.ckpt\"\n",
    "  file_name = create_checkpoint_file_name(\n",
    "   config_parsed = config_parsed,\n",
    "   date = date_string[-1],\n",
    "   training_images_count = training_images_count,\n",
    "   training_steps = str(config_parsed.max_training_steps),\n",
    "  )\n",
    "\n",
    "  # Move the checkpoint\n",
    "  shutil.move(last_checkpoint_file, os.path.join(trained_models_path, file_name))\n",
    "\n",
    " else:\n",
    "  checkpoints_directory = f\"{latest_training_directory}/checkpoints/trainstep_checkpoints\"\n",
    "  file_paths = glob.glob(f\"{checkpoints_directory}/*\")\n",
    "\n",
    "  for i, original_file_name in enumerate(file_paths):\n",
    "   # Remove the \"epoch=000000-step=0000\" text\n",
    "   steps = re.sub(checkpoints_directory + \"/epoch=\\d{6}-step=0*\", \"\", original_file_name)\n",
    "\n",
    "   # Remove the .ckpt\n",
    "   steps = steps.replace(\".ckpt\", \"\")\n",
    "\n",
    "   # Setup the filename\n",
    "   file_name = create_checkpoint_file_name(\n",
    "    config_parsed = config_parsed,\n",
    "    date = date_string[-1],\n",
    "    training_images_count = training_images_count,\n",
    "    training_steps = steps,\n",
    "   )\n",
    "\n",
    "   # Move the checkpoint\n",
    "   shutil.move(original_file_name, os.path.join(trained_models_path, file_name))\n",
    "\n",
    " print(\"✅ Download your trained model(s) from the 'trained_models' folder and use in your favorite Stable Diffusion repo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f14dd",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Optional - Upload to google drive\n",
    "* run the following commands in a new `terminal` in the `Dreambooth-Stable-Diffusion` directory\n",
    "* `chmod +x ./gdrive`\n",
    "* `./gdrive about`\n",
    "* `paste your token here after navigating to the link`\n",
    "* `./gdrive upload trained_models/{file_name.ckpt}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90ac5c",
   "metadata": {},
   "source": [
    "# Big Important Note!\n",
    "\n",
    "The way to use your token is `<token> <class>` ie `joepenna person` and not just `joepenna`"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
